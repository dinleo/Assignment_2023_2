{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T13:09:54.879131400Z",
     "start_time": "2023-10-15T13:09:54.868137400Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Similarity Queries\n",
    "==================\n",
    "\n",
    "Demonstrates querying a corpus for similar documents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T13:09:56.914272500Z",
     "start_time": "2023-10-15T13:09:56.893753900Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Corpus\n",
    "-------------------\n",
    "\n",
    "First, we need to create a corpus to work with.\n",
    "This step is the same as in the previous tutorial;\n",
    "if you completed it, feel free to skip to the next section.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T13:11:28.553626Z",
     "start_time": "2023-10-15T13:11:28.536597200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-15 22:11:28,535 : INFO : adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2023-10-15 22:11:28,536 : INFO : built Dictionary<12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...> from 9 documents (total 29 corpus positions)\n",
      "2023-10-15 22:11:28,537 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary<12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...> from 9 documents (total 29 corpus positions)\", 'datetime': '2023-10-15T22:11:28.537596', 'gensim': '4.3.2', 'python': '3.9.11 (tags/v3.9.11:2de452f, Mar 16 2022, 14:33:45) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from gensim import corpora\n",
    "\n",
    "documents = [\n",
    "    \"Human machine interface for lab abc computer applications\",\n",
    "    \"A survey of user opinion of computer system response time\",\n",
    "    \"The EPS user interface management system\",\n",
    "    \"System and human system engineering testing of EPS\",\n",
    "    \"Relation of user perceived response time to error measurement\",\n",
    "    \"The generation of random binary unordered trees\",\n",
    "    \"The intersection graph of paths in trees\",\n",
    "    \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "    \"Graph minors A survey\",\n",
    "]\n",
    "\n",
    "# remove common words and tokenize\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [\n",
    "    [word for word in document.lower().split() if word not in stoplist]\n",
    "    for document in documents\n",
    "]\n",
    "\n",
    "# remove words that appear only once\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "texts = [\n",
    "    [token for token in text if frequency[token] > 1]\n",
    "    for text in texts\n",
    "]\n",
    "\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity interface\n",
    "--------------------\n",
    "\n",
    "In the previous tutorials on\n",
    "`sphx_glr_auto_examples_core_run_corpora_and_vector_spaces.py`\n",
    "and\n",
    "`sphx_glr_auto_examples_core_run_topics_and_transformations.py`,\n",
    "we covered what it means to create a corpus in the Vector Space Model and how\n",
    "to transform it between different vector spaces. A common reason for such a\n",
    "charade is that we want to determine **similarity between pairs of\n",
    "documents**, or the **similarity between a specific document and a set of\n",
    "other documents** (such as a user query vs. indexed documents).\n",
    "\n",
    "To show how this can be done in gensim, let us consider the same corpus as in the\n",
    "previous examples (which really originally comes from Deerwester et al.'s\n",
    "`\"Indexing by Latent Semantic Analysis\" <http://www.cs.bham.ac.uk/~pxt/IDA/lsa_ind.pdf>`_\n",
    "seminal 1990 article).\n",
    "To follow Deerwester's example, we first use this tiny corpus to define a 2-dimensional\n",
    "LSI space:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T13:11:32.831031800Z",
     "start_time": "2023-10-15T13:11:32.793032100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-15 22:11:32,791 : INFO : using serial LSI version on this node\n",
      "2023-10-15 22:11:32,792 : INFO : updating model with new documents\n",
      "2023-10-15 22:11:32,793 : INFO : preparing a new chunk of documents\n",
      "2023-10-15 22:11:32,795 : INFO : using 100 extra samples and 2 power iterations\n",
      "2023-10-15 22:11:32,796 : INFO : 1st phase: constructing (12, 102) action matrix\n",
      "2023-10-15 22:11:32,796 : INFO : orthonormalizing (12, 102) action matrix\n",
      "2023-10-15 22:11:32,799 : INFO : 2nd phase: running dense svd on (12, 9) matrix\n",
      "2023-10-15 22:11:32,800 : INFO : computing the final decomposition\n",
      "2023-10-15 22:11:32,801 : INFO : keeping 2 factors (discarding 43.156% of energy spectrum)\n",
      "2023-10-15 22:11:32,801 : INFO : processed documents up to #9\n",
      "2023-10-15 22:11:32,802 : INFO : topic #0(3.341): 0.644*\"system\" + 0.404*\"user\" + 0.301*\"eps\" + 0.265*\"response\" + 0.265*\"time\" + 0.240*\"computer\" + 0.221*\"human\" + 0.206*\"survey\" + 0.198*\"interface\" + 0.036*\"graph\"\n",
      "2023-10-15 22:11:32,804 : INFO : topic #1(2.542): -0.623*\"graph\" + -0.490*\"trees\" + -0.451*\"minors\" + -0.274*\"survey\" + 0.167*\"system\" + 0.141*\"eps\" + 0.113*\"human\" + -0.107*\"response\" + -0.107*\"time\" + 0.072*\"interface\"\n",
      "2023-10-15 22:11:32,805 : INFO : LsiModel lifecycle event {'msg': 'trained LsiModel<num_terms=12, num_topics=2, decay=1.0, chunksize=20000> in 0.01s', 'datetime': '2023-10-15T22:11:32.804030', 'gensim': '4.3.2', 'python': '3.9.11 (tags/v3.9.11:2de452f, Mar 16 2022, 14:33:45) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this tutorial, there are only two things you need to know about LSI.\n",
    "First, it's just another transformation: it transforms vectors from one space to another.\n",
    "Second, the benefit of LSI is that enables identifying patterns and relationships between terms (in our case, words in a document) and topics.\n",
    "Our LSI space is two-dimensional (`num_topics = 2`) so there are two topics, but this is arbitrary.\n",
    "If you're interested, you can read more about LSI here: `Latent Semantic Indexing <https://en.wikipedia.org/wiki/Latent_semantic_indexing>`_:\n",
    "\n",
    "Now suppose a user typed in the query `\"Human computer interaction\"`. We would\n",
    "like to sort our nine corpus documents in decreasing order of relevance to this query.\n",
    "Unlike modern search engines, here we only concentrate on a single aspect of possible\n",
    "similarities---on apparent semantic relatedness of their texts (words). No hyperlinks,\n",
    "no random-walk static ranks, just a semantic extension over the boolean keyword match:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T13:17:59.146967100Z",
     "start_time": "2023-10-15T13:17:59.121679400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.46182100453271635), (1, 0.0700276652790004)]\n"
     ]
    }
   ],
   "source": [
    "doc = \"Human computer interaction\"\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow]  # convert the query to LSI space\n",
    "print(vec_lsi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we will be considering `cosine similarity <http://en.wikipedia.org/wiki/Cosine_similarity>`_\n",
    "to determine the similarity of two vectors. Cosine similarity is a standard measure\n",
    "in Vector Space Modeling, but wherever the vectors represent probability distributions,\n",
    "`different similarity measures <http://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Symmetrised_divergence>`_\n",
    "may be more appropriate.\n",
    "\n",
    "Initializing query structures\n",
    "++++++++++++++++++++++++++++++++\n",
    "\n",
    "To prepare for similarity queries, we need to enter all documents which we want\n",
    "to compare against subsequent queries. In our case, they are the same nine documents\n",
    "used for training LSI, converted to 2-D LSA space. But that's only incidental, we\n",
    "might also be indexing a different corpus altogether.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T13:18:04.871587400Z",
     "start_time": "2023-10-15T13:18:04.849589Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-15 22:18:04,848 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n",
      "2023-10-15 22:18:04,850 : INFO : creating matrix with 9 documents and 2 features\n"
     ]
    }
   ],
   "source": [
    "from gensim import similarities\n",
    "index = similarities.MatrixSimilarity(lsi[corpus])  # transform corpus to LSI space and index it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><h4>Warning</h4><p>The class :class:`similarities.MatrixSimilarity` is only appropriate when the whole\n",
    "  set of vectors fits into memory. For example, a corpus of one million documents\n",
    "  would require 2GB of RAM in a 256-dimensional LSI space, when used with this class.\n",
    "\n",
    "  Without 2GB of free RAM, you would need to use the :class:`similarities.Similarity` class.\n",
    "  This class operates in fixed memory, by splitting the index across multiple files on disk, called shards.\n",
    "  It uses :class:`similarities.MatrixSimilarity` and :class:`similarities.SparseMatrixSimilarity` internally,\n",
    "  so it is still fast, although slightly more complex.</p></div>\n",
    "\n",
    "Index persistency is handled via the standard :func:`save` and :func:`load` functions:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T13:20:27.563906700Z",
     "start_time": "2023-10-15T13:20:27.230065Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-15 22:20:27,229 : INFO : MatrixSimilarity lifecycle event {'fname_or_handle': '/tmp/deerwester.index', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-10-15T22:20:27.229065', 'gensim': '4.3.2', 'python': '3.9.11 (tags/v3.9.11:2de452f, Mar 16 2022, 14:33:45) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'saving'}\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tmp/deerwester.index'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gensim\\utils.py:764\u001B[0m, in \u001B[0;36mSaveLoad.save\u001B[1;34m(self, fname_or_handle, separately, sep_limit, ignore, pickle_protocol)\u001B[0m\n\u001B[0;32m    763\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 764\u001B[0m     \u001B[43m_pickle\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfname_or_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpickle_protocol\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    765\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msaved \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m object\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n",
      "\u001B[1;31mTypeError\u001B[0m: file must have a 'write' attribute",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mindex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/tmp/deerwester.index\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m index \u001B[38;5;241m=\u001B[39m similarities\u001B[38;5;241m.\u001B[39mMatrixSimilarity\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/tmp/deerwester.index\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gensim\\utils.py:767\u001B[0m, in \u001B[0;36mSaveLoad.save\u001B[1;34m(self, fname_or_handle, separately, sep_limit, ignore, pickle_protocol)\u001B[0m\n\u001B[0;32m    765\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msaved \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m object\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[0;32m    766\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:  \u001B[38;5;66;03m# `fname_or_handle` does not have write attribute\u001B[39;00m\n\u001B[1;32m--> 767\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_smart_save\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfname_or_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseparately\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msep_limit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpickle_protocol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpickle_protocol\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gensim\\utils.py:611\u001B[0m, in \u001B[0;36mSaveLoad._smart_save\u001B[1;34m(self, fname, separately, sep_limit, ignore, pickle_protocol)\u001B[0m\n\u001B[0;32m    607\u001B[0m restores \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_save_specials(\n\u001B[0;32m    608\u001B[0m     fname, separately, sep_limit, ignore, pickle_protocol, compress, subname,\n\u001B[0;32m    609\u001B[0m )\n\u001B[0;32m    610\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 611\u001B[0m     \u001B[43mpickle\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpickle_protocol\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    612\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    613\u001B[0m     \u001B[38;5;66;03m# restore attribs handled specially\u001B[39;00m\n\u001B[0;32m    614\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj, asides \u001B[38;5;129;01min\u001B[39;00m restores:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gensim\\utils.py:1442\u001B[0m, in \u001B[0;36mpickle\u001B[1;34m(obj, fname, protocol)\u001B[0m\n\u001B[0;32m   1429\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpickle\u001B[39m(obj, fname, protocol\u001B[38;5;241m=\u001B[39mPICKLE_PROTOCOL):\n\u001B[0;32m   1430\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Pickle object `obj` to file `fname`, using smart_open so that `fname` can be on S3, HDFS, compressed etc.\u001B[39;00m\n\u001B[0;32m   1431\u001B[0m \n\u001B[0;32m   1432\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1440\u001B[0m \n\u001B[0;32m   1441\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1442\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mwb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m fout:  \u001B[38;5;66;03m# 'b' for binary, needed on Windows\u001B[39;00m\n\u001B[0;32m   1443\u001B[0m         _pickle\u001B[38;5;241m.\u001B[39mdump(obj, fout, protocol\u001B[38;5;241m=\u001B[39mprotocol)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\smart_open\\smart_open_lib.py:177\u001B[0m, in \u001B[0;36mopen\u001B[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, compression, transport_params)\u001B[0m\n\u001B[0;32m    174\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m transport_params \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    175\u001B[0m     transport_params \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m--> 177\u001B[0m fobj \u001B[38;5;241m=\u001B[39m \u001B[43m_shortcut_open\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    178\u001B[0m \u001B[43m    \u001B[49m\u001B[43muri\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    179\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    180\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    181\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbuffering\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbuffering\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    182\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    183\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    184\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnewline\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    185\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    186\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fobj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    187\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fobj\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\smart_open\\smart_open_lib.py:363\u001B[0m, in \u001B[0;36m_shortcut_open\u001B[1;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001B[0m\n\u001B[0;32m    360\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m    361\u001B[0m     open_kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124merrors\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m errors\n\u001B[1;32m--> 363\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _builtin_open(local_path, mode, buffering\u001B[38;5;241m=\u001B[39mbuffering, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mopen_kwargs)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/tmp/deerwester.index'"
     ]
    }
   ],
   "source": [
    "index.save('/tmp/deerwester.index')\n",
    "index = similarities.MatrixSimilarity.load('/tmp/deerwester.index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is true for all similarity indexing classes (:class:`similarities.Similarity`,\n",
    ":class:`similarities.MatrixSimilarity` and :class:`similarities.SparseMatrixSimilarity`).\n",
    "Also in the following, `index` can be an object of any of these. When in doubt,\n",
    "use :class:`similarities.Similarity`, as it is the most scalable version, and it also\n",
    "supports adding more documents to the index later.\n",
    "\n",
    "Performing queries\n",
    "++++++++++++++++++\n",
    "\n",
    "To obtain similarities of our query document against the nine indexed documents:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sims = index[vec_lsi]  # perform a similarity query against the corpus\n",
    "print(list(enumerate(sims)))  # print (document_number, document_similarity) 2-tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine measure returns similarities in the range `<-1, 1>` (the greater, the more similar),\n",
    "so that the first document has a score of 0.99809301 etc.\n",
    "\n",
    "With some standard Python magic we sort these similarities into descending\n",
    "order, and obtain the final answer to the query `\"Human computer interaction\"`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "for doc_position, doc_score in sims:\n",
    "    print(doc_score, documents[doc_position])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The thing to note here is that documents no. 2 (``\"The EPS user interface management system\"``)\n",
    "and 4 (``\"Relation of user perceived response time to error measurement\"``) would never be returned by\n",
    "a standard boolean fulltext search, because they do not share any common words with ``\"Human\n",
    "computer interaction\"``. However, after applying LSI, we can observe that both of\n",
    "them received quite high similarity scores (no. 2 is actually the most similar!),\n",
    "which corresponds better to our intuition of\n",
    "them sharing a \"computer-human\" related topic with the query. In fact, this semantic\n",
    "generalization is the reason why we apply transformations and do topic modelling\n",
    "in the first place.\n",
    "\n",
    "Where next?\n",
    "------------\n",
    "\n",
    "Congratulations, you have finished the tutorials -- now you know how gensim works :-)\n",
    "To delve into more details, you can browse through the `apiref`,\n",
    "see the `wiki` or perhaps check out `distributed` in `gensim`.\n",
    "\n",
    "Gensim is a fairly mature package that has been used successfully by many individuals and companies, both for rapid prototyping and in production.\n",
    "That doesn't mean it's perfect though:\n",
    "\n",
    "* there are parts that could be implemented more efficiently (in C, for example), or make better use of parallelism (multiple machines cores)\n",
    "* new algorithms are published all the time; help gensim keep up by `discussing them <http://groups.google.com/group/gensim>`_ and `contributing code <https://github.com/piskvorky/gensim/wiki/Developer-page>`_\n",
    "* your **feedback is most welcome** and appreciated (and it's not just the code!):\n",
    "  `bug reports <https://github.com/piskvorky/gensim/issues>`_ or\n",
    "  `user stories and general questions <http://groups.google.com/group/gensim/topics>`_.\n",
    "\n",
    "Gensim has no ambition to become an all-encompassing framework, across all NLP (or even Machine Learning) subfields.\n",
    "Its mission is to help NLP practitioners try out popular topic modelling algorithms\n",
    "on large datasets easily, and to facilitate prototyping of new algorithms for researchers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img = mpimg.imread('run_similarity_queries.png')\n",
    "imgplot = plt.imshow(img)\n",
    "_ = plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
